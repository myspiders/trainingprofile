{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-03T14:29:20.102857Z",
     "start_time": "2019-05-03T14:29:20.097875Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from math import log\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-03T13:49:36.329515Z",
     "start_time": "2019-05-03T13:49:36.275499Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self):\n",
    "        self.mytree=None\n",
    "    \n",
    "    def  cal_entropy(self,datasets):#计算某一列的信息熵\n",
    "        num1=len(datasets)\n",
    "        labelcount={}\n",
    "        for num in datasets:\n",
    "            labelcount1=datasets.count(num)#统计各个标签出现的次数\n",
    "            labelcount[num]=labelcount1\n",
    "        entropy=-sum([(entropy1/num1)*log(entropy1/num1,2) for entropy1 in labelcount.values()])\n",
    "        return entropy \n",
    "        \n",
    "    def condational_entropy(self,datasets,axis=0):#先指定计算某一列的经验条件熵\n",
    "        num1=len(datasets)\n",
    "        featuresaxis=[]\n",
    "        for i in range(num1):\n",
    "            featurescate=datasets[i][axis]#把数据集中的单独一列挑选出来，并放入featureaxis,此函数默认为第一列\n",
    "            featuresaxis.append(featurescate)\n",
    "        uniquefeatures=list(set(featuresaxis))#看单独一列中有那些属性值\n",
    "        cond_entropy=0\n",
    "        for feauture in uniquefeatures:#分别筛选特征值\n",
    "            data=[]\n",
    "            for k in range(num1):\n",
    "                if datasets[k][axis]==feauture:\n",
    "                    data.append(datasets[k][-1])\n",
    "                    cal=self.cal_entropy(data)\n",
    "            cond_entropy+=(len(data)/num1)*cal\n",
    "        return cond_entropy\n",
    "    \n",
    "    def max_gain(self,datasets):#计算每一列的信息增益，并挑选出信息增益最大的列所对应的索引值\n",
    "        feauturecount=len(datasets[0])\n",
    "        num1genjiedian=len(datasets)\n",
    "        genjiedian=[]#单独拿出根节点，并计算根节点的信息熵\n",
    "        for c in range(num1genjiedian):\n",
    "            genjiedian.append(datasets[c][-1])\n",
    "        ent=self.cal_entropy(genjiedian)\n",
    "        gaininfo=[]\n",
    "        for m in range(feauturecount-1):\n",
    "            cond_entropy=self.condational_entropy(datasets,m)\n",
    "            gain=ent-cond_entropy#计算每一个属性的信息增益\n",
    "            gaininfo.append(gain)\n",
    "        maxindex=gaininfo.index(max(gaininfo))\n",
    "        #print('信息增益最大的节点是：'+str(maxindex)+'，值为：'+str(max(gaininfo)))\n",
    "        return maxindex\n",
    "    \n",
    "    def splitData(self,trainData,index,value):#计算子集，即后续划分的数据集，目的是返回最佳属性对应的特征值，将不同的特征值筛选出来\n",
    "        subData = []\n",
    "        for trainLine in trainData:\n",
    "            if trainLine[index]==value:#这一行会将第index+1列与values相等的所有行均选出来\n",
    "                reducedFeatVec = []\n",
    "                for i in range(len(trainLine)):#循环将所有非index+1列的行数据添加到列表中\n",
    "                    if i==index:#跳过第index+1列\n",
    "                        continue\n",
    "                    reducedFeatVec.append(trainLine[i])\n",
    "                subData.append(reducedFeatVec)\n",
    "        return subData\n",
    "\n",
    "    def fit(self,traindata):#树是一个多重嵌套的字典结构\n",
    "        classlist=[temp[-1] for temp in traindata]\n",
    "        classset=set(classlist)#看根节点有多数个不同的标签，如果所有标签都是同一个值，则直接将其作为决策树节点，并结束决策树划分\n",
    "        if len(classset)==1:\n",
    "            return classlist[0]\n",
    "        if len(traindata[0])==1:#如果特征集为空，只有标签集，即只有D存在，则将D中最大的类Dk作为标签\n",
    "            mk={}\n",
    "            for c in traindata[0]:\n",
    "                mk1=traindata[0].count(c)\n",
    "                mk[c]=mk1\n",
    "            return max(mk,key=mk.get)\n",
    "        best_feature=self.max_gain(traindata)#计算当前数据集的最佳属性对应的索引\n",
    "        mytree={best_feature:{}}\n",
    "        featurevalues=[example[best_feature] for example in traindata]\n",
    "        uniquefeature=list(set(featurevalues))\n",
    "        for values in uniquefeature:\n",
    "            mytree[best_feature][values]=self.fit(self.splitData(traindata,best_feature,values))#递归实现树结构\n",
    "        self.mytree=mytree\n",
    "        return mytree\n",
    "            \n",
    "    def classify(self,testData,dTrees):#这里假设testdata为一个一维的数组\n",
    "        index = list(dTrees.keys())[0]\n",
    "        secondDict = dTrees[index]#该属性下对应的树结构\n",
    "        testValue = testData[index]#测试集相应属性的值\n",
    "        for key in secondDict.keys():\n",
    "            if testValue==key:#按照属性相应的值进行查找\n",
    "                if type(secondDict[key])==dict:\n",
    "                    secondTest = copy.deepcopy(testData)\n",
    "                    del secondTest[index]#删掉每一次递归重复的\n",
    "                    classLabel = classify(secondTest,secondDict[key])#递归查找结果\n",
    "                else:\n",
    "                    classLabel = secondDict[key]\n",
    "        return classLabel\n",
    "    \n",
    "    def predict(self,testdata):#testdata为一个具有多个测试样本的二维数组\n",
    "        classlabel1=[]\n",
    "        for testline in testdata:\n",
    "            classlabel=self.classify(testline,self.mytree)\n",
    "            classlabel1.append(classlabel)\n",
    "        return classlabel1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-03T12:38:13.908671Z",
     "start_time": "2019-05-03T12:38:13.893670Z"
    }
   },
   "outputs": [],
   "source": [
    " datasets = [['青年', '否', '否', '一般', '否'],\n",
    "               ['青年', '否', '否', '好', '否'],\n",
    "               ['青年', '是', '否', '好', '是'],\n",
    "               ['青年', '是', '是', '一般', '是'],\n",
    "               ['青年', '否', '否', '一般', '否'],\n",
    "               ['中年', '否', '否', '一般', '否'],\n",
    "               ['中年', '否', '否', '好', '否'],\n",
    "               ['中年', '是', '是', '好', '是'],\n",
    "               ['中年', '否', '是', '非常好', '是'],\n",
    "               ['中年', '否', '是', '非常好', '是'],\n",
    "               ['老年', '否', '是', '非常好', '是'],\n",
    "               ['老年', '否', '是', '好', '是'],\n",
    "               ['老年', '是', '否', '好', '是'],\n",
    "               ['老年', '是', '否', '非常好', '是'],\n",
    "               ['老年', '否', '否', '一般', '否'],\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-03T14:34:47.193747Z",
     "start_time": "2019-05-03T14:34:47.179765Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['否']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt=DecisionTree()\n",
    "best=dt.max_gain(datasets)\n",
    "dt1=dt.fit(datasets)\n",
    "dt.predict([['老年', '否', '否', '一般']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
